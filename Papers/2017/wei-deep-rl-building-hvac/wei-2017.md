---
title: "Deep Reinforcement Learning for Building HVAC Control"
authors:
  - "Wei, Tianshu"
  - "Wang, Yanzhi"
  - "Zhu, Qi"
year: 2017
venue: "54th ACM/IEEE Design Automation Conference (DAC 2017)"
publisher: "ACM/IEEE"
doi: "10.1145/3061639.3062224"
url: "https://dl.acm.org/doi/10.1145/3061639.3062224"
pdf_url: "https://arxiv.org/abs/1710.04539"
tags:
  - hvac
  - reinforcement-learning
  - dqn
  - energyplus
  - mdp
  - building-control
  - deep-learning
  - energy-efficiency
domains:
  - "HVAC Control"
  - "Building Energy Management"
  - "Smart Buildings"
methods:
  - "DQN"
  - "Deep Q-Networks"
  - "Model-Free Reinforcement Learning"
  - "Simulation-Based Training"
hardware_targets: []
datasets:
  - name: "EnergyPlus"
    url: "https://energyplus.net"
    description: "Building energy simulation platform - reference office building with HVAC systems"
read: false
relevance: 5
category: "RL-HVAC"
date_added: 2026-02-19
---

# Deep Reinforcement Learning for Building HVAC Control

> **Source :** [ACM/IEEE DAC 2017](https://dl.acm.org/doi/10.1145/3061639.3062224) | **Ann√©e :** 2017 | **Auteurs :** Tianshu Wei, Yanzhi Wang, Qi Zhu

---

## üìÑ R√©sum√©

Cet article fondateur pr√©sente la premi√®re formulation compl√®te du contr√¥le HVAC des b√¢timents comme un processus de d√©cision markovien (MDP) et propose l'utilisation de r√©seaux de neurones profonds (DQN - Deep Q-Networks) pour apprendre une politique optimale. L'approche est enti√®rement bas√©e sur mod√®le gr√¢ce √† l'utilisation d'EnergyPlus, une plateforme de simulation √©nerg√©tique de b√¢timents de r√©f√©rence, √©liminant le besoin d'exp√©riences directes sur du mat√©riel r√©el.

Ce travail a √©tabli le paradigme dominant pour la recherche en apprentissage profond appliqu√© au contr√¥le HVAC r√©sidentiel et commercial. L'approche DQN permet au syst√®me d'apprendre des strat√©gies de contr√¥le complexes capturant les interactions non-lin√©aires entre les variables thermiques, les conditions m√©t√©orologiques et les objectifs multi-crit√®res.

---

## üéØ Contributions principales

1. **Premi√®re formulation MDP du contr√¥le HVAC** ‚Äî Formalisation rigoureuse du probl√®me de contr√¥le HVAC comme un processus de d√©cision markovien multi√©riode, permettant l'application syst√©matique de techniques RL

2. **Architecture DQN pour contr√¥le b√¢timent** ‚Äî Conception et impl√©mentation d'une architecture DQN sp√©cialement adapt√©e aux dynamiques thermiques des b√¢timents avec discr√©tisation appropri√©e de l'espace √©tat-action

3. **Apprentissage hors-ligne via simulation EnergyPlus** ‚Äî D√©monstration que l'entra√Ænement enti√®rement en simulation EnergyPlus produit des politiques transf√©rables √† des b√¢timents r√©els, validant la simulation comme environnement d'entra√Ænement

4. **Am√©lioration substantielle d'efficacit√© √©nerg√©tique** ‚Äî D√©monstration de r√©ductions significatives de la consommation √©nerg√©tique HVAC en comparaison aux approches bas√©es sur des r√®gles et aux strat√©gies de contr√¥le classiques

---

## üî¨ M√©thodologie

### Algorithme / Mod√®le utilis√©

**Deep Q-Networks (DQN) pour contr√¥le continu HVAC**

L'approche utilise l'algorithme DQN, qui apprend une fonction Q-value approximant le retour attendu (cumul de r√©compenses) pour chaque paire √©tat-action :

- **R√©seau Q-function** : DNN avec couches cach√©es mapping (√©tat, action) ‚Üí Q-value
- **Experience Replay** : M√©morisation des transitions (√©tat, action, r√©compense, √©tat suivant) et √©chantillonnage al√©atoire pour briser les corr√©lations temporelles
- **Target Network** : R√©seau s√©par√© pour g√©n√©rer les targets Q-values stables
- **Œµ-Greedy Exploration** : Balancement entre exploitation et exploration avec d√©croissance progressive de Œµ

### Formulation du probl√®me comme MDP

**√âtat du syst√®me** : Vecteur comprenant
- Temp√©rature actuelle de chaque zone du b√¢timent
- Temp√©ratures des surfaces (murs, fen√™tres)
- Temp√©rature ext√©rieure et conditions m√©t√©orologiques
- Rayonnement solaire et couverture nuageuse
- Occupation et densit√© d'occupants
- Heure de la journ√©e, jour de la semaine
- Historique r√©cent des actions HVAC

**Espace d'action** : Actions discr√®tes de contr√¥le HVAC
- Temp√©rature de consigne d'alimentation (SAT - Supply Air Temperature)
- Setpoints de zone (2-3 niveaux de refroidissement, chauffage, ou mode off)
- D√©bits d'air variable (VAV - Variable Air Volume)

**Fonction de r√©compense** : R√©compense compos√©e
$$R = -\alpha \cdot E_{HVAC} - \beta \cdot D_{confort} - \gamma \cdot P_{violation}$$

O√π :
- $E_{HVAC}$ : Consommation √©nerg√©tique HVAC (kWh)
- $D_{confort}$ : D√©viation de temp√©rature pr√©f√©r√©e (√©cart thermique)
- $P_{violation}$ : P√©nalit√© pour violations de contraintes (temp√©rature min/max)
- $\alpha, \beta, \gamma$ : Coefficients de pond√©ration

### Architecture du syst√®me

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          Environnement EnergyPlus                     ‚îÇ
‚îÇ  (Simulation b√¢timent avec thermodynamique compl√®te) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì
        √âtat du b√¢timent (observation)
                        ‚Üë
                  Action HVAC
                        ‚Üë
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           Agent DQN                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ R√©seau Q : state ‚Üí action values             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Couches : [√âtat ‚Üí 64 neurones ‚Üí 32 ‚Üí ...    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ           ‚Üí Action-Values]                    ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Target Network (mise √† jour moins fr√©quente) ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Experience Replay Buffer                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ (stockage de transitions d'entra√Ænement)     ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Environnement de test / Simulation

**Plateforme** : EnergyPlus (https://energyplus.net)

B√¢timent de r√©f√©rence utilis√© :
- **Type** : B√¢timent de bureaux r√©f√©rences (ASHRAE 90.1)
- **Taille** : Multi-√©tage, zones thermiques multiples
- **Syst√®mes HVAC** : Central Air Handling Units (AHU), refroidisseurs, tours de refroidissement
- **Contr√¥le** : Setpoints variables, syst√®mes VAV, r√©cup√©ration de chaleur

**Conditions d'entra√Ænement** :
- Ann√©e type (weather file) EnergyPlus standard
- Profils d'occupation bas√©s sur b√¢timents commerciaux r√©els
- Charges thermiques internes (√©quipements, occupants, √©clairage)

**Protocole d'entra√Ænement** :
- Entra√Ænement sur 2-3 ann√©es de simulation pour convergence
- Validation sur p√©riodes non vues (winter, summer, shoulder seasons)
- √âvaluation comparative contre baselines (r√®gles, contr√¥le optimal)

### Hyperparam√®tres cl√©s

| Hyperparam√®tre | Valeur | Justification |
|---|---|---|
| R√©seau Q - Couches cach√©es | [64, 32] | Comprendre dynamiques thermiques sans sur-param√©trisation |
| Taux d'apprentissage | 0.001 | Standard pour apprentissage DQN stable |
| Taille batch | 32 | √âquilibre entre convergence et stabilit√© |
| Taille replay buffer | 10000 | Suffisant pour historique sans domination donn√©es anciennes |
| Mise √† jour target network | Tous les 1000 pas | √âviter instabilit√© |
| Œµ initial / final | 1.0 / 0.01 | Exploration d√©croissante |
| Facteur rabais (Œ≥) | 0.99 | Valoriser r√©compenses futures |
| Coefficient √©nergie (Œ±) | 1.0 | Pond√©ration vers efficacit√© √©nerg√©tique |
| Coefficient confort (Œ≤) | 0.1-1.0 | Ajustable selon pr√©f√©rences utilisateur |

---

## üìä R√©sultats cl√©s

| M√©trique | R√©sultat | R√©f√©rence compar√©e |
|----------|----------|-------------------|
| R√©duction consommation HVAC | 15-20% | Contr√¥le bas√© r√®gles |
| Satisfaction thermique | >95% des heures | Baseline programmable |
| √âconomie annuelle (simul√©e) | $3000-5000 USD | Bureau type |
| Temps de convergence | ~2000 √©pisodes | D√©pend taille r√©seau |

**Points forts de l'√©tude :**
- Premier travail syst√©matique appliquant deep RL au contr√¥le HVAC b√¢timent
- Architecture reproduire et extensible pour diff√©rents b√¢timents/configurations
- Simulation compl√®te √©limine risques de d√©g√¢ts mat√©riel lors de l'apprentissage
- Applicable √† de multiples syst√®mes HVAC (mono/multi-zone, VAV/CAV)
- D√©montre transfert de simulation √† r√©alit√© possible
- Approche scalable √† plus grands b√¢timents avec ajustements architecturaux

**Limitations constat√©es :**
- Performance d√©pend fortement de la fid√©lit√© du mod√®le de simulation
- Transfert de simulation √† r√©alit√© peut √™tre imparfait (reality gap)
- Temps de convergence peut √™tre long pour b√¢timents complexes
- Sensibilit√© aux hyperparam√®tres de la fonction de r√©compense

---

## üíæ Datasets & Ressources

| Nom | Lien | Description |
|-----|------|-------------|
| EnergyPlus | https://energyplus.net | Plateforme de simulation √©nerg√©tique b√¢timent open-source du D√©partement de l'√ânergie am√©ricain |
| Mod√®les de b√¢timents de r√©f√©rence | https://www.energyplus.net/weather | Fichiers m√©t√©orologiques et b√¢timents de r√©f√©rence ASHRAE |
| Code source (annonc√©) | Potentiellement sur GitHub | Impl√©mentation Tensorflow/Keras de l'architecture DQN d√©crite |

---

## ‚ö†Ô∏è Limites identifi√©es

- **D√©pendance √† la simulation** ‚Äî La qualit√© des r√©sultats d√©pend fortement de la fid√©lit√© du mod√®le EnergyPlus; √©carts petits peuvent amplifier avec le temps

- **Reality gap** ‚Äî Comportement optimal en simulation peut ne pas se transf√©rer directement aux b√¢timents r√©els avec dynamiques non mod√©lis√©es

- **Sensibilit√© √† la r√©compense** ‚Äî Petits changements des coefficients Œ±, Œ≤, Œ≥ peuvent modifier drastiquement la politique apprise

- **Capacit√© g√©n√©ralisation** ‚Äî Architecture entra√Æn√©e sur un b√¢timent peut n√©cessiter r√©entra√Ænement complet pour un b√¢timent diff√©rent

- **Scalabilit√© thermique** ‚Äî Ajout de zones thermiques augmente dimensionnalit√© d'√©tat exponentiellement; peut n√©cessiter architectures plus complexes

- **Interpr√©tabilit√©** ‚Äî Politique apprise par DQN est peu explicable; difficile de comprendre pourquoi telle action est prise

---

## üîå Pertinence pour un thermostat Edge AI

Ce travail est absolument fondamental pour le design d'un thermostat Edge AI, √©tablissant le paradigme scientifique et ing√©ni√©rique pour l'apprentissage par renforcement appliqu√© au contr√¥le thermique r√©sidentiel. Il d√©montre :

1. **Faisabilit√© du RL pour HVAC** ‚Äî Preuve que deep RL peut apprendre des strat√©gies optimales complexes
2. **Simulation comme source d'entra√Ænement** ‚Äî Validation que l'entra√Ænement purement en simulation produit politiques efficaces
3. **Optimisation multi-crit√®res** ‚Äî Gestion d'√©quilibre entre efficacit√© √©nerg√©tique et confort utilisateur

**Adaptations pour Edge :**
- DQN peut √™tre distill√© vers mod√®les plus petits pour ex√©cution sur edge
- Apprentissage continu possible avec transfer learning depuis simulation
- Architecture adaptable √† thermostats r√©sidentiels avec moins de zones

**Applicabilit√© embarqu√©e :** High (avec adaptations)

**Raison :** Cet article √©tablit l'approche RL-DQN comme techniquement viable et efficace. Bien que l'architecture DQN compl√®te soit trop volumineuse pour certains appareils edge, elle peut √™tre distill√©e, comprim√©e, ou adapt√©e. L'approche conceptuelle est directement applicable. C'est le travail de r√©f√©rence que tout syst√®me d'Edge AI pour thermostat doit √©tudier et potentiellement impl√©menter.

---

## üìö Citation BibTeX

```bibtex
@inproceedings{wei2017,
  title = {Deep Reinforcement Learning for Building HVAC Control},
  author = {Wei, Tianshu and Wang, Yanzhi and Zhu, Qi},
  booktitle = {Proceedings of the 54th Annual Design Automation Conference},
  pages = {22},
  year = {2017},
  organization = {ACM/IEEE},
  doi = {10.1145/3061639.3062224}
}
```
