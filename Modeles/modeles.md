---
title: "Catalogue des ModÃ¨les â€” IA pour Thermostats Intelligents"
description: "Inventaire exhaustif des architectures ML/DL/RL utilisÃ©es dans la littÃ©rature HVAC : paramÃ¨tres, couches, quantisation, matÃ©riel d'entraÃ®nement et d'infÃ©rence, performances"
date_created: 2026-02-19
tags:
  - modeles
  - architecture
  - quantisation
  - edge-ai
  - benchmarks
  - hardware
categories_covered:
  - Reinforcement Learning (DQN, D3QN, DDPG, ED-DQN, BDQ, MAB)
  - LSTM & RNN
  - CNN-LSTM hybrides
  - TinyML / Edge embarquÃ©
  - Baselines (PID, rule-based)
---

# ğŸ§  Catalogue des ModÃ¨les â€” IA pour Thermostats Intelligents

> **Mise Ã  jour :** 2026-02-19 Â· **ModÃ¨les documentÃ©s :** 20+ architectures Â· **Sources :** papiers scientifiques + benchmarks matÃ©riels

---

## ğŸ—ºï¸ Navigation rapide

| CatÃ©gorie | ModÃ¨les | Aller Ã  |
|-----------|---------|---------|
| ğŸ® Reinforcement Learning | DQN Â· D3QN Â· DDPG Â· ED-DQN Â· BDQ Â· MAB Â· Q-Learning tabular | [â†’](#-reinforcement-learning) |
| ğŸ” LSTM & RNN | LSTM basic Â· LSTM lÃ©ger Â· MH-LSTM Â· GA-LSTM Â· PSO-LSTM | [â†’](#-lstm--rnn) |
| ğŸ”€ CNN-LSTM hybrides | CNN-LSTM + Attention Â· BO CNN-M-LSTM Â· Digital Twin LSTM | [â†’](#-cnn-lstm-hybrides) |
| ğŸ”Œ TinyML / Edge AI | Random Forest ESP32 Â· TDL sub-KB Â· Frameworks | [â†’](#-tinyml--edge-ai) |
| ğŸ“ Baselines | PID Â· Rule-based | [â†’](#-baselines) |
| ğŸ–¥ï¸ Hardware benchmarks | ESP32 Â· STM32 Â· Arduino Â· Cortex-M | [â†’](#ï¸-benchmarks-hardware) |
| ğŸ“Š Tableau comparatif | Tous les modÃ¨les | [â†’](#-tableau-comparatif-global) |

---

## ğŸ® Reinforcement Learning

> Les modÃ¨les RL apprennent une politique de contrÃ´le par interaction avec une simulation (EnergyPlus). L'infÃ©rence est lÃ©gÃ¨re â€” c'est l'entraÃ®nement qui est coÃ»teux.

---

### DQN â€” Deep Q-Network (standard)

> **Papier sÃ©minal du domaine.** Introduit par Wei et al. (2017).

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| **Architecture** | MLP 2 couches : [64 â†’ 32] |
| **ParamÃ¨tres** | ~3 000 â€“ 5 000 |
| **MÃ©moire FP32** | ~12 â€“ 20 KB |
| **MÃ©moire INT8** | ~3 â€“ 5 KB |
| **Quantisation testÃ©e** | âŒ Non mentionnÃ©e dans les papiers |
| **EntraÃ®nement** | CPU/GPU + EnergyPlus (simulation) |
| **InfÃ©rence cible** | Serveur cloud |
| **Convergence** | ~2 000 Ã©pisodes |
| **Ã‰conomie Ã©nergie** | 15â€“20 % vs thermostat classique |
| **Satisfaction confort** | >95 % des heures |

**Papier source :** [[Papers/2017/wei-deep-rl-building-hvac/wei-2017|Wei et al. 2017]] Â· [[Papers/2019/dqn-hvac-energyplus/dqn-hvac-2019|DQN HVAC 2019]] Â· [[Papers/2020/gupta-dqn-energy-efficient-heating/gupta-2020|Gupta 2020]]

---

### D3QN â€” Double Dueling DQN

> Combinaison de Double DQN (correction overestimation) et Dueling DQN (streams valeur + avantage). Architecture optimale selon Qin et al. (2024).

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| **Architecture** | [64 â†’ 12] avec Value stream + Advantage stream |
| **ParamÃ¨tres** | ~4 000 â€“ 5 000 |
| **MÃ©moire FP32** | ~16 â€“ 20 KB |
| **MÃ©moire INT8** | ~4 â€“ 5 KB |
| **Quantisation testÃ©e** | âŒ Non testÃ©e dans le papier |
| **Quantisation possible** | âœ… (INT8 â†’ ~4 KB, bien adaptÃ© embarquÃ©) |
| **EntraÃ®nement** | CPU/GPU + EnergyPlus, 8 760 h/an simulÃ©es |
| **InfÃ©rence cible** | Edge / MCU capable |
| **Convergence** | ~320 Ã©pisodes (29 % plus rapide que DQN) |
| **Ã‰conomie Ã©nergie** | 24 % (projet 1) Â· 23 % Â· 20 % Â· 18 % |
| **Variance TÂ°** | 0,4 Â°C (vs 0,8 Â°C DQN) |
| **RÃ©sidu Q-error std** | 0,9 (vs 2,5 DQN) |

**Architecture interne :**
```
Input â†’ [FC 64] â†’ â”¬â†’ Value stream   [FC 32 â†’ scalar V(s)]
                  â””â†’ Advantage stream [FC 32 â†’ A(s,a) pour chaque action]
                  â””â†’ Q(s,a) = V(s) + A(s,a) - mean(A)
```

**Papier source :** [[Papers/2024/dqn-d3qn-hvac-comparison/dqn-d3qn-2024|DQN vs D3QN 2024]]

---

### ED-DQN â€” Event-Driven DQN

> Variante cruciale pour l'embarquÃ© : ne dÃ©clenche une dÃ©cision que lors d'un changement significatif. RÃ©duit de 76 % le nombre d'ajustements.

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| **Architecture** | [64 â†’ 64 â†’ 32] + mÃ©canisme event-triggering |
| **ParamÃ¨tres** | ~6 000 â€“ 8 000 |
| **MÃ©moire FP32** | ~24 â€“ 32 KB |
| **MÃ©moire INT8** | ~6 â€“ 8 KB |
| **Quantisation testÃ©e** | âŒ Non testÃ©e |
| **Quantisation possible** | âœ… TrÃ¨s adaptÃ© (faible nb de paramÃ¨tres) |
| **EntraÃ®nement** | CPU/GPU + EnergyPlus, 365 jours simulÃ©s, 3-5 zones |
| **InfÃ©rence cible** | **Edge embarquÃ©** (dÃ©cisions sparses) |
| **Convergence** | ~800 Ã©pisodes (vs 1 200 DQN standard) |
| **Ã‰conomie Ã©nergie** | 27 % vs thermostat baseline |
| **RÃ©duction ajustements** | **76 %** vs DQN standard |
| **Confort** | 88 % des heures dans Â±1 Â°C |
| **RMSE** | 0,35 Â°C |

**MÃ©canisme event-triggering :**
```
DÃ©clenchement si : |T_actuelle - T_rÃ©fÃ©rence| > seuil Îµ
â†’ Calcul action RL uniquement lors des Ã©vÃ©nements
â†’ RÃ©duit drastiquement la charge CPU et les usures mÃ©caniques
```

**Papier source :** [[Papers/2023/ed-dqn-event-driven-hvac/ed-dqn-2023|ED-DQN 2023]]

---

### DDPG â€” Deep Deterministic Policy Gradient

> Actor-Critic pour les espaces d'action **continus** (tempÃ©rature en Â°C, pas discrÃ¨te). Significativement plus complexe que DQN.

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| **Architecture** | Actor [FC 256 â†’ FC 128 â†’ action continue] + Critic [FC 256 â†’ FC 128 â†’ Q-value] |
| **ParamÃ¨tres** | ~15 000 â€“ 20 000 (double rÃ©seau) |
| **MÃ©moire FP32** | ~60 â€“ 80 KB |
| **MÃ©moire INT8** | ~15 â€“ 20 KB |
| **Quantisation testÃ©e** | âŒ Non mentionnÃ©e |
| **EntraÃ®nement** | GPU/CPU + EnergyPlus multi-zones rÃ©sidentielles |
| **InfÃ©rence cible** | Serveur ou edge haut de gamme |
| **Convergence** | 300 â€“ 500 Ã©pisodes |
| **vs DQN** | **âˆ’15 % coÃ»t Ã©nergÃ©tique**, **âˆ’79 % violations confort** |
| **vs rule-based** | **âˆ’98 % violations confort** |
| **PrÃ©cision TÂ°** | Â±0,5 Â°C |
| **Transfert** | GÃ©nÃ©ralise sur de nouveaux bÃ¢timents non vus |

**Papier source :** [[Papers/2024/du-ddpg-multizone-residential/du-ddpg-2024|Du DDPG multi-zones]]

---

### BDQ â€” Branching Dueling Q-Network (OCTOPUS)

> Architecture pour les espaces d'action trÃ¨s larges (2,3M+ combinaisons). ContrÃ´le simultanÃ© HVAC + Ã©clairage + stores + fenÃªtres.

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| **Architecture** | Extraction partagÃ©e [FC 128 â†’ FC 64] + 4 branches dueling indÃ©pendantes |
| **ParamÃ¨tres** | ~25 000 â€“ 35 000 |
| **MÃ©moire FP32** | ~100 â€“ 140 KB |
| **MÃ©moire INT8** | ~25 â€“ 35 KB |
| **Quantisation testÃ©e** | âŒ Non testÃ©e |
| **EntraÃ®nement** | GPU + EnergyPlus, LEED Gold, 10 ans mÃ©tÃ©o, Merced CA + Chicago IL |
| **InfÃ©rence cible** | Serveur |
| **Espace d'action original** | 6,25 M combinaisons â†’ rÃ©duit Ã  ~8 000 via branches |
| **Convergence** | ~200 Ã©pisodes (~200 jours simulÃ©s) |
| **Ã‰conomie Ã©nergie** | **14,26 %** vs rule-based |
| **Ã‰conomie coÃ»t annuel** | 14,3 % ($307/an) |
| **Confort** | 82â€“88 % (vs 75â€“80 % baseline) |

**Papier source :** [[Papers/2024/octopus-holistic-building-drl/octopus-2024|OCTOPUS 2024]]

---

### Expert-Guided DRL

> DRL accÃ©lÃ©rÃ© par 3 fonctions d'expertise hÃ©tÃ©rogÃ¨nes : physique, donnÃ©es historiques, rÃ¨gles heuristiques.

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| **Base** | DQN ou PPO + 3 guidance functions |
| **ParamÃ¨tres** | ~10 000 â€“ 20 000 (dÃ©pend de la base) |
| **Quantisation testÃ©e** | âŒ Non testÃ©e |
| **EntraÃ®nement** | GPU + EnergyPlus |
| **AccÃ©lÃ©ration convergence** | **8,8Ã— plus rapide** vs DRL non guidÃ© |
| **Ã‰pisodes requis** | 100 â€“ 300 (vs 1 000 â€“ 3 000 baseline) |
| **Violations** | 2 â€“ 5 % (vs 15 â€“ 25 % sans guidage) |

**Papier source :** [[Papers/2025/efficient-rl-expert-guided-hvac/expert-rl-2025|Expert-guided RL 2025]]

---

### Event-Triggered TD â€” MIT LIDS (Hosseinloo 2020)

> ModÃ¨le **tabulaire** event-triggered. Converge en **1 semaine** de donnÃ©es rÃ©elles. Directement embarquable sur MCU.

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| **Architecture** | Q-table ou V-table sparse + politique Ï€ |
| **ParamÃ¨tres** | Tabulaire (adaptatif, ~quelques KB) |
| **MÃ©moire** | **<5 KB** |
| **MÃ©moire INT8** | **<2 KB** |
| **Quantisation** | âœ… N/A (tabulaire, nativement lÃ©ger) |
| **EntraÃ®nement** | **BÃ¢timent rÃ©el** (campus MIT), donnÃ©es in-situ |
| **InfÃ©rence cible** | **MicrocontrÃ´leur** |
| **Convergence** | **1 semaine** de donnÃ©es rÃ©elles (exceptionnel) |
| **RÃ©duction dÃ©cisions** | **50 â€“ 90 %** vs contrÃ´le Ã  temps fixe |

**Papier source :** [[Papers/2020/hosseinloo-mit-event-triggered-rl/hosseinloo-2020|Hosseinloo MIT 2020]]

---

### Multi-Armed Bandit â€” Thompson Sampling (Elehwany 2023)

> Apprentissage des prÃ©fÃ©rences de tempÃ©rature depuis les **overrides implicites** de l'occupant. ZÃ©ro feedback explicite requis.

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| **Architecture** | Thompson Sampling, distributions Beta par action |
| **ParamÃ¨tres** | ~11 distributions (1 par action) â€” **<1 KB** |
| **MÃ©moire** | **<5 KB** |
| **Quantisation** | âœ… N/A (modÃ¨le probabiliste) |
| **EntraÃ®nement** | **In-situ** (bÃ¢timent rÃ©el via overrides) |
| **InfÃ©rence cible** | **MicrocontrÃ´leur** |
| **Convergence** | 45 â€“ 60 jours |
| **PrÃ©cision prÃ©fÃ©rences** | 87 % (vs 82 % UCB) |
| **Ã‰conomie hiver** | 15,2 % Â· **Ã©tÃ©** : 10,1 % Â· **annuel** : 12,6 % |

**Papier source :** [[Papers/2023/setpoint-preference-learning-rl/setpoint-preference-2023|Setpoint preference RL 2023]]

---

### Q-Learning tabulaire (Barrett 2015)

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| **Architecture** | Q-table + Bayesian occupancy inference |
| **ParamÃ¨tres** | Tabulaire adaptatif |
| **MÃ©moire** | ~quelques KB |
| **EntraÃ®nement** | DonnÃ©es rÃ©sidentielles rÃ©elles |
| **InfÃ©rence cible** | MCU / thermostat embarquÃ© |
| **Ã‰conomie** | 10 % vs thermostat programmable |

**Papier source :** [[Papers/2015/barrett-linder-autonomous-hvac-rl/barrett-linder-2015|Barrett & Linder 2015]]

---

## ğŸ” LSTM & RNN

---

### LSTM lÃ©ger â€” 50 851 paramÃ¨tres (2025)

> â­ **Le plus important pour l'embarquÃ©.** ConÃ§u explicitement pour dÃ©ploiement sur microcontrÃ´leur.

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| **Architecture** | 1-2 couches LSTM [32-64 units] + Dense [16] + Dropout [0.2-0.5] |
| **ParamÃ¨tres** | **50 851** |
| **MÃ©moire FP32** | **203,4 KB** |
| **MÃ©moire INT8 estimÃ©e** | **~51 KB** |
| **MÃ©moire FP16 estimÃ©e** | **~102 KB** |
| **Quantisation testÃ©e** | âŒ Non testÃ©e dans le papier (mais recommandÃ©e) |
| **EntraÃ®nement** | CPU/GPU, cross-validation rolling window (5-10 folds) |
| **InfÃ©rence cible** | **MicrocontrÃ´leur** (Cortex-M4/M7, ESP32-S3) |
| **Loss** | 0,0004709 â€“ 0,0282 |
| **RÂ²** | 0,90 â€“ 0,95 |
| **TÃ¢che** | PrÃ©diction TÂ° intÃ©rieure (1â€“4 h d'avance) |

**Note quantisation :** Si quantifiÃ© INT8 via TFLite Micro â†’ ~51 KB, dÃ©ployable sur ESP32 (520 KB SRAM) ou STM32 Cortex-M4 (128â€“256 KB RAM).

**Papier source :** [[Papers/2025/ml-indoor-temp-lightweight/ml-indoor-temp-2025|ML Indoor Temp Lightweight 2025]]

---

### LSTM standard â€” prÃ©diction multi-zones (Mtibaa 2020)

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| **Architecture** | 1-2 couches LSTM [64â€“256 units], Seq2Seq encodeur-dÃ©codeur |
| **ParamÃ¨tres** | ~30 000 â€“ 100 000 |
| **MÃ©moire FP32** | ~120 â€“ 400 KB |
| **MÃ©moire INT8** | ~30 â€“ 100 KB |
| **Quantisation testÃ©e** | âŒ Non testÃ©e |
| **EntraÃ®nement** | GPU/CPU, donnÃ©es rÃ©elles bÃ¢timent VAV/CAV |
| **InfÃ©rence cible** | Serveur ou edge haut de gamme |
| **vs MLP** | âˆ’50 % d'erreur de prÃ©diction |
| **RMSE** | 0,3 â€“ 0,8 Â°C |
| **MAE** | 0,2 â€“ 0,6 Â°C |
| **RÂ²** | 0,90 â€“ 0,95 |

**Papier source :** [[Papers/2020/lstm-indoor-temp-prediction/lstm-indoor-2020|LSTM Indoor Temp 2020]]

---

### MH-LSTM â€” Multi-Head LSTM (Cho et al. 2024)

> 3 tÃªtes LSTM capturant des dynamiques court/moyen/long terme en parallÃ¨le. Confort thermique personnalisÃ©.

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| **Architecture** | 3 tÃªtes LSTM parallÃ¨les + fusion + Dense |
| **TÃªte 1 (court terme)** | 6 timesteps (~1-2 h), 64 units |
| **TÃªte 2 (moyen terme)** | 24 timesteps (~8 h), 64 units |
| **TÃªte 3 (long terme)** | 96 timesteps (~24 h+), 64 units |
| **ParamÃ¨tres** | ~50 000 |
| **MÃ©moire FP32** | ~200 KB |
| **MÃ©moire INT8** | ~50 KB |
| **Quantisation testÃ©e** | âŒ Non testÃ©e |
| **EntraÃ®nement** | CPU/GPU, 6 participants Ã— 4 semaines, ~10 000 pts/participant |
| **InfÃ©rence cible** | Edge (capable MCU) |
| **PrÃ©cision classification** | **92 %** (vs 84â€“86 % LSTM standard) |
| **F1-Score** | 0,90 |
| **Sortie** | Ã‰chelle de sensation thermique 7 niveaux (âˆ’3 Ã  +3) |

**Papier source :** [[Papers/2024/cho-mh-lstm-personalized-comfort/cho-mh-lstm-2024|MH-LSTM Thermal Comfort 2024]]

---

### GA-LSTM â€” Optimisation par Algorithme GÃ©nÃ©tique

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| **Architecture** | LSTM [64 â†’ 32] + Dense [16] + Dropout, poids optimisÃ©s par AG |
| **ParamÃ¨tres** | ~30 000 â€“ 40 000 |
| **MÃ©moire FP32** | ~120 â€“ 160 KB |
| **Quantisation testÃ©e** | âŒ Non testÃ©e |
| **EntraÃ®nement** | Population 30 Â· 100 gÃ©nÃ©rations Â· mutation 0,1 Â· ~8 h |
| **vs LSTM standard** | âˆ’36 % RMSE |
| **Accuracy** | 93,2 % Â· F1 0,931 |
| **TÃ¢che** | PrÃ©diction d'occupation (15â€“30 min) |

**Papier source :** [[Papers/2023/occupancy-lstm-optimized/occupancy-lstm-2023|Occupancy LSTM 2023]]

---

### PSO-LSTM â€” Optimisation par Essaim de Particules

> â­ **Meilleure prÃ©cision** des trois variantes (standard, GA, PSO). Convergence plus rapide que GA.

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| **Architecture** | LSTM [64 â†’ 32] + Dense [16], poids optimisÃ©s par PSO |
| **ParamÃ¨tres** | ~30 000 â€“ 40 000 |
| **MÃ©moire FP32** | ~120 â€“ 160 KB |
| **Quantisation testÃ©e** | âŒ Non testÃ©e |
| **EntraÃ®nement** | 20-30 particules Â· 200-500 itÃ©rations Â· ~3 h (vs 8 h GA) |
| **vs LSTM standard** | **âˆ’46 % RMSE** |
| **Accuracy** | **94,8 %** Â· F1 **0,946** Â· ROC-AUC **0,965** |
| **RÃ©duction erreur 15 min** | âˆ’56 % |
| **RÃ©duction erreur 30 min** | âˆ’34 % |

**Papier source :** [[Papers/2023/occupancy-lstm-optimized/occupancy-lstm-2023|Occupancy LSTM 2023]]

---

## ğŸ”€ CNN-LSTM hybrides

---

### CNN-LSTM + Attention (Elmaz et al. 2021)

> Architecture encodeur-dÃ©codeur avec mÃ©canisme d'attention. Optimisation bayÃ©sienne des hyperparamÃ¨tres.

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| **Architecture** | Conv1D [32 filtres] â†’ Conv1D [64 filtres] â†’ MaxPooling â†’ BiLSTM [128] encodeur â†’ LSTM [128] dÃ©codeur â†’ Attention |
| **ParamÃ¨tres** | ~50 000 â€“ 70 000 |
| **MÃ©moire FP32** | ~200 â€“ 280 KB |
| **MÃ©moire INT8** | ~50 â€“ 70 KB |
| **Quantisation testÃ©e** | âŒ Non testÃ©e |
| **Optimisation HP** | Bayesian Optimization (TPE), 100-200 configurations |
| **EntraÃ®nement** | GPU, bÃ¢timent rÃ©el UniversitÃ© d'Anvers, 1â€“5 min granularitÃ© |
| **InfÃ©rence cible** | Edge haut de gamme |
| **Gain vs LSTM (1 min)** | +15â€“25 % |
| **Gain vs LSTM (60 min)** | +25â€“40 % |
| **Gain vs LSTM (120 min)** | **+30â€“45 %** |

**Papier source :** [[Papers/2021/cnn-lstm-predictive-indoor-temp/cnn-lstm-2021|CNN-LSTM 2021]]

---

### BO CNN-M-LSTM â€” Bayesian Optimized (2025)

> CNN + LSTM multivariÃ© avec optimisation bayÃ©sienne. Double sortie : prÃ©diction de charge + confort PMV.

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| **Architecture** | Conv1D [filtres, kernel] â†’ MaxPooling â†’ M-LSTM multivariÃ© â†’ 2 tÃªtes de sortie |
| **ParamÃ¨tres** | ~40 000 â€“ 60 000 |
| **MÃ©moire FP32** | ~160 â€“ 240 KB |
| **MÃ©moire INT8** | ~40 â€“ 60 KB |
| **Quantisation testÃ©e** | âŒ Non testÃ©e |
| **Espace de recherche HP** | Filtres CNN [16,32,64] Â· Kernel [3,5,7] Â· LSTM [32,64,128] Â· Dropout [0.1,0.3,0.5] Â· LR [1e-4,1e-3] |
| **EntraÃ®nement** | GPU, bÃ¢timents commerciaux + ASHRAE DB, 1â€“2 ans donnÃ©es |
| **InfÃ©rence cible** | Serveur / edge haut de gamme |
| **Load forecast MAPE** | 5â€“10 % |
| **Confort PMV MAE** | Â±0,3 unitÃ©s |
| **RÂ² load** | 0,85 â€“ 0,92 |

**Papier source :** [[Papers/2025/bayesian-cnn-m-lstm-comfort/cnn-m-lstm-2025|Bayesian CNN-M-LSTM 2025]]

---

### Digital Twin LSTM-Attention (2025)

> Jumeau numÃ©rique physique couplÃ© Ã  un BiLSTM avec multi-head attention. InterprÃ©tabilitÃ© + prÃ©cision.

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| **Architecture** | RC thermal model (physics) + BiLSTM [64-128 units] + Multi-head Attention [4-8 heads, dim 32-64] + 3 tÃªtes sortie |
| **ParamÃ¨tres** | ~80 000 â€“ 120 000 |
| **MÃ©moire FP32** | ~320 â€“ 480 KB |
| **MÃ©moire INT8** | ~80 â€“ 120 KB |
| **Quantisation testÃ©e** | âŒ Non testÃ©e |
| **EntraÃ®nement** | GPU essentiel, EnergyPlus ou donnÃ©es rÃ©elles multi-zones |
| **InfÃ©rence cible** | Serveur / cloud (complexitÃ© Ã©levÃ©e) |
| **SÃ©quence d'entrÃ©e** | 168 timesteps (1 semaine historique) |
| **Horizon de prÃ©diction** | 24 â€“ 48 pas en avant |
| **RÃ©duction Ã©nergie** | **14 %** vs setpoint fixe |
| **ProductivitÃ© occupants** | **+22 %** estimÃ© |
| **RÂ²** | 0,85 â€“ 0,92 |

**Papier source :** [[Papers/2025/digital-twin-lstm-hvac/digital-twin-lstm-2025|Digital Twin LSTM 2025]]

---

## ğŸ”Œ TinyML / Edge AI

---

### Random Forest sur ESP32 (TinyML 2026)

> â­ **RÃ©fÃ©rence embarquÃ©e directe.** DÃ©ployÃ© et mesurÃ© sur ESP32 rÃ©el.

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| **ModÃ¨le** | Random Forest (6 candidats testÃ©s : LR, KNN, DT, Gradient Boosting, RF, XGBoost) |
| **Gagnant** | Random Forest |
| **Stockage** | **1,426 MB** (sur 4â€“16 MB Flash ESP32) |
| **Latence d'infÃ©rence** | **997 Âµs** (< 1 ms !) |
| **Quantisation** | âœ… Natif (arbres = opÃ©rations entiÃ¨res) |
| **Hardware** | ESP32 (Xtensa LX6/LX7, 240 MHz, 520 KB SRAM) |
| **Capteurs d'entrÃ©e** | COâ‚‚, TÂ°, HumiditÃ©, LumiÃ¨re, PrÃ©sence PIR |
| **RÂ²** | **0,923** |
| **Framework** | micromlgen / scikit-learn â†’ C |

**Outil de dÃ©ploiement :**
```
scikit-learn â†’ micromlgen â†’ C/C++ statique â†’ ESP32 flash
Taille FLASH : 1.4 MB  |  RAM : ~<50 KB  |  Latence : 997 Âµs
```

**Papier source :** [[Papers/2026/tinyml-occupancy-esp32/tinyml-esp32-2026|TinyML ESP32 2026]]

---

### TDL â€” Tiny Deep Learning sub-kilobyte (2026)

> ModÃ¨les dont l'empreinte mÃ©moire est **infÃ©rieure Ã  1 KB**. Quantisation + pruning extrÃªmes.

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| **ModÃ¨le** | RÃ©seau de neurones ultra-lÃ©ger avec quantisation + pruning |
| **Taille modÃ¨le** | **< 1 KB** (sub-kilobyte) |
| **Quantisation** | âœ… INT8 ou moins (quantisation agressive) |
| **Pruning** | âœ… SparsitÃ© Ã©levÃ©e |
| **Hardware cible** | MCU ultra-contraints |
| **Ã‰nergie/infÃ©rence** | Ã‰valuÃ©e (incl. Ã©missions COâ‚‚ Ã©q.) |
| **TÃ¢che** | DÃ©tection d'occupation temps rÃ©el |
| **Performance** | Haute performance maintenue malgrÃ© contraintes extrÃªmes |

**Papier source :** [[Papers/2026/sustainability-tiny-deep-learning/sustainability-tdl-2026|Sustainability TDL 2026]]

---

### Frameworks TinyML de rÃ©fÃ©rence

| Framework | Cible | Quantisation | Notes |
|-----------|-------|-------------|-------|
| **TensorFlow Lite Micro (TFLM)** | ARM Cortex-M, ESP32 | INT8 âœ… | Standard de facto, optimisÃ© CMSIS-NN |
| **Edge Impulse** | ESP32, STM32, Arduino | INT8 âœ… | MLOps cloud â†’ MCU, pipeline complet |
| **X-CUBE-AI (STM32)** | STM32 Cortex-M4/M7 | INT8 âœ… | Plus rapide que TFLM sur STM32 |
| **ESP-DL** | ESP32-S3 | INT8 âœ… | 4.5â€“6.25Ã— accÃ©lÃ©ration hardware |
| **micromlgen** | ESP32, Arduino | Natif âœ… | sklearn â†’ C, parfait pour RF/DT |
| **emlearn** | MCU C99 | Natif âœ… | RF en ~2 KB FLASH |
| **CMSIS-NN** | Cortex-M4/M7 | INT8 âœ… | 4.6Ã— speedup vs baseline |

**Papiers source :** [[Papers/2022/schizas-tinyml-iot-review/schizas-tinyml-2022|Schizas TinyML 2022]] Â· [[Papers/2025/edge-intelligence-tinyml-cities/tinyml-cities-2025|TinyML Cities 2025]]

---

## ğŸ“ Baselines

---

### PID â€” Proportional-Integral-Derivative

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| **ParamÃ¨tres** | 3 (K_p, K_i, K_d) |
| **MÃ©moire** | NÃ©gligeable |
| **Hardware** | Tout MCU, mÃªme 8 bits |
| **Tuning** | Ziegler-Nichols ou empirique |
| **Violations confort** | 1â€“2 Â°C de moyenne (vs <0,5 Â°C RL) |
| **Robustesse perturbations** | Bonne mais infÃ©rieure au RL |
| **StabilitÃ©** | Excellente, prouvÃ©e |

**Papier source :** [[Papers/2025/rl-vs-pid-hvac-simulation/rl-pid-2025|RL vs PID 2025]]

---

### Thermostat Ã  rÃ¨gles fixes

> Baseline systÃ©matique dans tous les papiers. Setpoint fixe ou planning jour/nuit.

| RÃ©sultat | Valeur |
|----------|--------|
| **vs DDPG** | +98 % violations confort |
| **vs Dueling DQN** | Ã‰conomie Ã©nergie 4.8â€“39.58 % possible |
| **vs ED-DQN** | 27 % d'Ã©nergie supplÃ©mentaire consommÃ©e |

---

## ğŸ–¥ï¸ Benchmarks Hardware

> DonnÃ©es issues de publications et benchmarks officiels (MLPerf Tiny, CMSIS-NN, etc.)

### Performances comparÃ©es des MCU cibles

| Plateforme | CPU | RAM | Flash | Latence LSTM typ. | Latence RF typ. | Quantisation |
|-----------|-----|-----|-------|-----------------|----------------|-------------|
| **ESP32** | Xtensa LX6 240 MHz | 520 KB | 4â€“16 MB | ~74 ms | **997 Âµs** | INT8 via TFLM |
| **ESP32-S3** | Xtensa LX7 240 MHz | 512 KB | 8 MB | ~55 ms | <1 ms | INT8 + ESP-DL |
| **STM32 Cortex-M4 @ 120 MHz** | ARM M4 120 MHz | 128â€“320 KB | 256â€“512 KB | 50â€“200 ms | <5 ms | INT8 CMSIS-NN |
| **STM32 Cortex-M7 @ 480 MHz** | ARM M7 480 MHz | 1 MB | 2 MB | 20â€“80 ms | <2 ms | INT8 CMSIS-NN |
| **Arduino Nano BLE 33** | ARM M4 64 MHz | 256 KB | 1 MB | 100â€“400 ms | <10 ms | INT8 TFLM |
| **Portenta H7** | M7 480 + M4 240 MHz | 1 MB | 2 MB | 20â€“60 ms | <2 ms | INT8 TFLM |
| **Ambiq Apollo3 (Cortex-M4F)** | ARM M4F 96 MHz | 384 KB | 1 MB | ~100 ms | <5 ms | INT8 FQT |

### Impact de la quantisation (rÃ©sultats publiÃ©s)

| Technique | RÃ©duction taille | Vitesse | Perte prÃ©cision | Notes |
|-----------|----------------|---------|----------------|-------|
| **FP32 â†’ INT8** | **4Ã— â€“ 10Ã—** | **2â€“4Ã—** | 1â€“5 % | Standard TinyML |
| **FP32 â†’ FP16** | **2Ã—** | 1,5Ã— | <1 % | GPU principalement |
| **FP32 â†’ INT8 (DQN)** | 4Ã— | **2,2Ã— â€“ 5,4Ã—** | Maintenue | Arxiv 2019 |
| **LSTM 16Ã—8** | 2Ã— | 1,5Ã— | ~1 % | Meilleur pour RNN |
| **LSTM 8Ã—8** | 4Ã— | 3Ã— | âš ï¸ DÃ©gradation notable | Ã€ Ã©viter sans QAT |
| **Pruning 50 %** | 2Ã— | 1,3Ã— | 1â€“3 % | Combinable avec quant. |
| **CMSIS-NN (M4)** | = | **4,6Ã—** | 0 % | Optimisation kernels ARM |

> **Recommandation pour LSTM :** PrivilÃ©gier quantisation **16Ã—8** (poids 16 bits, activations 8 bits) plutÃ´t que 8Ã—8 pure. Pour les modÃ¨les RL/DQN, INT8 fonctionne bien avec un entraÃ®nement aware (QAT).

### Latences d'infÃ©rence mesurÃ©es dans les papiers

| ModÃ¨le | Hardware | Latence | Source |
|--------|---------|---------|--------|
| Random Forest | ESP32 | **997 Âµs** | [[Papers/2026/tinyml-occupancy-esp32/tinyml-esp32-2026\|TinyML ESP32 2026]] |
| LSTM 1 couche (mÃ©tÃ©o) | ESP32 | 74 ms | MDPI Sensors 2025 |
| LSTM 1 couche (mÃ©tÃ©o) | ESP32-S3 | 55 ms | MDPI Sensors 2025 |
| NN (occupancy ToF) | MCU non spÃ©cifiÃ© | 275 ms | MDPI 2024 |
| TinyML gÃ©nÃ©ral | ESP32 â†’ Portenta | 21 ms â€“ >1 s | [[Papers/2025/edge-intelligence-tinyml-cities/tinyml-cities-2025\|TinyML Cities 2025]] |
| CMSIS-NN CNN | Cortex-M4 | 3,47 â€“ 14,98 ms | PMC 2021 |

---

## ğŸ“Š Tableau comparatif global

| ModÃ¨le | Type | Params | RAM FP32 | RAM INT8 | Quant. testÃ©e | HW train | HW infÃ©rence | Ã‰conomie Ã©nergie | PrÃ©cision / Confort | Papier |
|--------|------|--------|---------|---------|-------------|---------|-------------|-----------------|--------------------|----|
| **Event-Triggered TD** | RL tabulaire | <1 K | <5 KB | <2 KB | âœ… N/A | BÃ¢timent rÃ©el | **MCU** | Optimal | Excellent | [[Papers/2020/hosseinloo-mit-event-triggered-rl/hosseinloo-2020\|2020]] |
| **MAB Thompson** | RL bandit | <1 K | <5 KB | <2 KB | âœ… N/A | In-situ | **MCU** | 12,6 % | 87 % prefs | [[Papers/2023/setpoint-preference-learning-rl/setpoint-preference-2023\|2023]] |
| **DQN standard** | RL valeur | 3â€“5 K | 12â€“20 KB | 3â€“5 KB | âŒ | CPU/GPU | Serveur | 15â€“20 % | >95 % h. | [[Papers/2017/wei-deep-rl-building-hvac/wei-2017\|2017]] |
| **D3QN** | RL valeur | 4â€“5 K | 16â€“20 KB | 4â€“5 KB | âŒ | CPU/GPU | Edge | **24 %** | 0,4 Â°C var | [[Papers/2024/dqn-d3qn-hvac-comparison/dqn-d3qn-2024\|2024]] |
| **ED-DQN** | RL event | 6â€“8 K | 24â€“32 KB | 6â€“8 KB | âŒ | CPU/GPU | **Edge** | **27 %** | 88 % Â±1 Â°C | [[Papers/2023/ed-dqn-event-driven-hvac/ed-dqn-2023\|2023]] |
| **Expert-Guided DRL** | RL guidÃ© | 10â€“20 K | 40â€“80 KB | 10â€“20 KB | âŒ | GPU | Serveur | Optimal | 8,8Ã— conv. | [[Papers/2025/efficient-rl-expert-guided-hvac/expert-rl-2025\|2025]] |
| **DDPG** | RL acteur-critique | 15â€“20 K | 60â€“80 KB | 15â€“20 KB | âŒ | GPU | Serveur | +15 % / DQN | Â±0,5 Â°C | [[Papers/2024/du-ddpg-multizone-residential/du-ddpg-2024\|2024]] |
| **BDQ (OCTOPUS)** | RL branching | 25â€“35 K | 100â€“140 KB | 25â€“35 KB | âŒ | GPU | Serveur | 14,26 % | 82â€“88 % | [[Papers/2024/octopus-holistic-building-drl/octopus-2024\|2024]] |
| **Random Forest** | ML classique | ~N/A | 1,4 MB flash | âœ… natif | âœ… natif | CPU | **ESP32** | N/A | RÂ²=0,923 | [[Papers/2026/tinyml-occupancy-esp32/tinyml-esp32-2026\|2026]] |
| **TDL sub-KB** | DL ultra-lÃ©ger | <qq K | **<1 KB** | âœ… | âœ… | CPU | **Ultra-MCU** | N/A | Ã‰levÃ©e | [[Papers/2026/sustainability-tiny-deep-learning/sustainability-tdl-2026\|2026]] |
| **LSTM lÃ©ger** | RNN | **50 851** | **203 KB** | **~51 KB** | âŒ | CPU/GPU | **MCU** | N/A | RÂ²=0,90â€“0,95 | [[Papers/2025/ml-indoor-temp-lightweight/ml-indoor-temp-2025\|2025]] |
| **PSO-LSTM** | RNN+mÃ©taheuristique | 30â€“40 K | 120â€“160 KB | 30â€“40 KB | âŒ | CPU | Edge | N/A | 94,8 % acc. | [[Papers/2023/occupancy-lstm-optimized/occupancy-lstm-2023\|2023]] |
| **MH-LSTM** | RNN multi-tÃªte | 50 K | 200 KB | ~50 KB | âŒ | CPU/GPU | Edge | N/A | **92 %** class. | [[Papers/2024/cho-mh-lstm-personalized-comfort/cho-mh-lstm-2024\|2024]] |
| **CNN-LSTM + Attn** | Hybride | 50â€“70 K | 200â€“280 KB | 50â€“70 KB | âŒ | GPU | Edge haut | N/A | +30â€“45 % vs LSTM | [[Papers/2021/cnn-lstm-predictive-indoor-temp/cnn-lstm-2021\|2021]] |
| **BO CNN-M-LSTM** | Hybride | 40â€“60 K | 160â€“240 KB | 40â€“60 KB | âŒ | GPU | Serveur/edge | N/A | RÂ²=0,85â€“0,92 | [[Papers/2025/bayesian-cnn-m-lstm-comfort/cnn-m-lstm-2025\|2025]] |
| **DT LSTM-Attention** | Hybride+physique | 80â€“120 K | 320â€“480 KB | 80â€“120 KB | âŒ | GPU | Serveur | **14 %** | RÂ²=0,85â€“0,92 | [[Papers/2025/digital-twin-lstm-hvac/digital-twin-lstm-2025\|2025]] |
| **PID** | ContrÃ´le classique | 3 params | NÃ©gligeable | âœ… natif | âœ… natif | N/A | **Tout MCU** | RÃ©fÃ©rence 0 % | 1â€“2 Â°C violations | [[Papers/2025/rl-vs-pid-hvac-simulation/rl-pid-2025\|2025]] |

---

## ğŸ”‘ Constat clÃ© sur la quantisation

> **Aucun des papiers HVAC analysÃ©s ne teste explicitement la quantisation de ses modÃ¨les.** C'est un **gap de recherche** majeur et une opportunitÃ© directe pour le projet de thermostat Edge AI.

La littÃ©rature gÃ©nÃ©rale TinyML montre que :
- **INT8** fonctionne trÃ¨s bien pour les modÃ¨les RL (DQN) : 2,2â€“5,4Ã— speedup, prÃ©cision maintenue.
- **LSTM 16Ã—8** est prÃ©fÃ©rable Ã  8Ã—8 pur pour Ã©viter la dÃ©gradation.
- **Random Forest** est nativement adaptÃ© au MCU (pas de quantisation nÃ©cessaire).
- **Pruning + quantisation combinÃ©s** peuvent rÃ©duire un modÃ¨le 10â€“20Ã— tout en maintenant >95 % de prÃ©cision.

---

*Catalogue gÃ©nÃ©rÃ© le 2026-02-19 â€” BasÃ© sur 27 papiers scientifiques + benchmarks matÃ©riels publiÃ©s*
